{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-04T16:53:04.972227Z","iopub.execute_input":"2024-11-04T16:53:04.972612Z","iopub.status.idle":"2024-11-04T16:53:05.340529Z","shell.execute_reply.started":"2024-11-04T16:53:04.972574Z","shell.execute_reply":"2024-11-04T16:53:05.339772Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:53:05.342291Z","iopub.execute_input":"2024-11-04T16:53:05.343055Z","iopub.status.idle":"2024-11-04T16:53:39.018753Z","shell.execute_reply.started":"2024-11-04T16:53:05.343007Z","shell.execute_reply":"2024-11-04T16:53:39.017530Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nfrom huggingface_hub import interpreter_login\nimport os\n\ninterpreter_login()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:53:39.020405Z","iopub.execute_input":"2024-11-04T16:53:39.020750Z","iopub.status.idle":"2024-11-04T16:54:25.932668Z","shell.execute_reply.started":"2024-11-04T16:53:39.020715Z","shell.execute_reply":"2024-11-04T16:54:25.931686Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your token (input will not be visible):  ·····································\nAdd token as git credential? (Y/n)  n\n"},{"name":"stdout","text":"Token is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# disable Weights and Biases\nos.environ['WANDB_DISABLED']=\"true\"\nos.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"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\"","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:54:25.934620Z","iopub.execute_input":"2024-11-04T16:54:25.934968Z","iopub.status.idle":"2024-11-04T16:54:25.939334Z","shell.execute_reply.started":"2024-11-04T16:54:25.934932Z","shell.execute_reply":"2024-11-04T16:54:25.938357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"snli_dataset_train = load_dataset(\"stanfordnlp/snli\", split=\"train\")\nsnli_dataset_val = load_dataset(\"stanfordnlp/snli\", split=\"validation\")\nsnli_dataset_test = load_dataset(\"stanfordnlp/snli\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:54:25.940906Z","iopub.execute_input":"2024-11-04T16:54:25.941238Z","iopub.status.idle":"2024-11-04T16:54:32.986072Z","shell.execute_reply.started":"2024-11-04T16:54:25.941206Z","shell.execute_reply":"2024-11-04T16:54:32.985151Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18215640af0944bfa979b63f72166259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/412k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ad6bdefd9744766832e140fcf20d478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/413k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18b4c2425f3e4d1d97981d4c0786e79f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653ac3769aef48e5811a0631f407e2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4888fa72b424cc4b5146ad18787d8db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bfd528e8f87450a8048db056e9fb8ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8f431ba6b245839735e5c321cfd4b8"}},"metadata":{}}]},{"cell_type":"code","source":"# Select every 550th sample for the new training data\nnew_train_dataset = snli_dataset_train.select(range(0, len(snli_dataset_train), 550))\n\n# Select every 100th sample for the new validation data\nnew_val_dataset = snli_dataset_val.select(range(0, len(snli_dataset_val), 100))\n\n# Select every 100th sample for the new testing data\nnew_test_dataset = snli_dataset_test.select(range(0, len(snli_dataset_test), 100))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:54:32.987367Z","iopub.execute_input":"2024-11-04T16:54:32.987756Z","iopub.status.idle":"2024-11-04T16:54:33.006973Z","shell.execute_reply.started":"2024-11-04T16:54:32.987714Z","shell.execute_reply":"2024-11-04T16:54:33.005868Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:54:33.008245Z","iopub.execute_input":"2024-11-04T16:54:33.008629Z","iopub.status.idle":"2024-11-04T16:54:33.018278Z","shell.execute_reply.started":"2024-11-04T16:54:33.008586Z","shell.execute_reply":"2024-11-04T16:54:33.017364Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model_name='microsoft/phi-2'\ndevice_map = {\"\": 0}\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:54:33.019477Z","iopub.execute_input":"2024-11-04T16:54:33.019868Z","iopub.status.idle":"2024-11-04T16:56:49.984159Z","shell.execute_reply.started":"2024-11-04T16:54:33.019821Z","shell.execute_reply":"2024-11-04T16:56:49.983175Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce1ae1d96d31494eba6f48a2750cbf33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9079dd11764746e2a812bff54ee13932"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb5a90c28fd4e45b42f7552a4e60b69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e7ce58c1ee4456aebd43e0bb35d8b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ee7c9691ef4242ade06106ec657897"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d001cd9681e4ead8befdeada6f25823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"670797547c6f43a3bb4176ec113ed71c"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:56:49.985264Z","iopub.execute_input":"2024-11-04T16:56:49.985558Z","iopub.status.idle":"2024-11-04T16:56:51.918343Z","shell.execute_reply.started":"2024-11-04T16:56:49.985528Z","shell.execute_reply":"2024-11-04T16:56:51.917366Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56c66f4a7104f4b8f34ce42f43894a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55a0114ab1e4190b855f44e93eb45f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ca4a9ca138b4dd288f68be575ecab89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea7f1887fbb4461a5b6c7a3653655ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4eabad8333a46bea8e703e01b675594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec5cb2eedd34b8aac574cc621300bfa"}},"metadata":{}}]},{"cell_type":"code","source":"%%time\nfrom transformers import set_seed\nseed = 42\nset_seed(seed)\n\n# max_length = 0\n\n# for index in range(len(new_test_dataset)):\n#     max_length = max(max_length, len(formatted_prompt.format(new_test_dataset[index]['premise'], new_test_dataset[index]['hypothesis'])))\n    \n#     print(\"Max_length\", max_length)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\noutput_labels_before_finetuning = []\n\n\ndef zero_shot_inference(model, tokenizer, premise, hypothesis):\n    # Create a formatted prompt\n    formatted_prompt = f\"\"\"Instruct: Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n    0 -> Hypothesis entails the Premise\n    1 -> Premise and Hypothesis neither entail nor contradict each other \n    2 -> Hypothesis contradicts the Premise \n    Output only one single numerical value.\n\n    Premise: {premise}\n    Hypothesis: {hypothesis}\n\n    Output:\n    \"\"\"\n    \n    # Tokenize the input\n    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     print(\"input_ids: \", input_ids)\n#     print(\"Len: \", input_ids.size(1))\n    model.to(input_ids.device)\n    \n    # Generate output\n    with torch.no_grad():\n        generated_ids = model.generate(input_ids, max_length=input_ids.size(1)+64)\n        \n    # Decode and process the model's output\n    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    answer = None\n    try:\n        answer = int((output.split(\"Output:\\n\")[-1].strip().split(\"\\n\")[0]).split(\" \")[0])\n    except:\n        answer = None\n    return formatted_prompt, answer\n\n# Example data for entailment\ncorrect = 0\ntotal = len(new_test_dataset)\nincorrect = 0\nfor index in range(0, len(new_test_dataset)):\n    \n    print(\"Index: \", index)\n    \n    premise = new_test_dataset[index]['premise']\n    hypothesis = new_test_dataset[index]['hypothesis']\n    original_label = new_test_dataset[index]['label']\n\n    # Perform zero-shot inference\n    formatted_prompt, output = zero_shot_inference(original_model, tokenizer, premise, hypothesis)\n    \n#     print(\"Output: \", output)\n    \n#     print(\"Len of prompt: \", len(formatted_prompt))\n    \n    if(output==None):\n        total-=1\n        incorrect+=1\n    elif(int(output) == original_label):\n        correct+=1\n        \n    output_labels_before_finetuning.append(int(output))\n        \n#     break\n\n# Print results\ndash_line = '-' * 100\nprint(dash_line)\n# print(f'INPUT PROMPT:\\n{formatted_prompt}')\n# print(dash_line)\n# print(f'BASELINE LABEL:\\n{original_label}\\n')\n# print(dash_line)\n# print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\naccuracy = correct/total * 100\n\nprint(\"Accuracy before fine-tuning: \", accuracy)\nprint(\"Samples in incorrect format: \", incorrect)\n\n\n# print(output)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:56:51.922814Z","iopub.execute_input":"2024-11-04T16:56:51.923986Z","iopub.status.idle":"2024-11-04T17:02:53.872460Z","shell.execute_reply.started":"2024-11-04T16:56:51.923939Z","shell.execute_reply":"2024-11-04T17:02:53.871564Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Index:  0\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  1\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  2\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  3\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  4\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  5\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  6\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  7\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  8\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  9\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  10\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  11\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  12\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  13\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  14\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  15\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  16\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  17\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  18\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  19\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  20\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  21\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  22\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  23\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  24\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  25\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  26\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  27\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  28\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  29\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  30\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  31\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  32\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  33\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  34\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  35\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  36\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  37\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  38\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  39\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  40\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  41\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  42\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  43\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  44\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  45\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  46\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  47\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  48\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  49\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  50\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  51\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  52\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  53\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  54\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  55\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  56\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  57\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  58\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  59\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  60\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  61\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  62\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  63\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  64\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  65\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  66\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  67\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  68\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  69\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  70\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  71\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  72\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  73\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  74\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  75\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  76\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  77\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  78\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  79\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  80\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  81\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  82\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  83\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  84\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  85\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  86\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  87\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  88\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  89\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  90\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  91\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  92\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  93\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  94\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  95\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  96\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  97\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  98\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  99\n----------------------------------------------------------------------------------------------------\nAccuracy before fine-tuning:  41.0\nSamples in incorrect format:  0\nCPU times: user 6min 1s, sys: 286 ms, total: 6min 1s\nWall time: 6min 1s\n","output_type":"stream"}]},{"cell_type":"code","source":"formatted_prompt = f\"\"\"Instruct: Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n    0 -> Hypothesis entails the Premise\n    1 -> Premise and Hypothesis neither entail nor contradict each other \n    2 -> Hypothesis contradicts the Premise\n    Output only one single numerical value.\n\n    Premise: {new_train_dataset[0]['premise']}\n    Hypothesis: {new_train_dataset[0]['hypothesis']}\n\n    Output:\n\"\"\"\n\nprint(len(formatted_prompt))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:02:53.873720Z","iopub.execute_input":"2024-11-04T17:02:53.874119Z","iopub.status.idle":"2024-11-04T17:02:53.880881Z","shell.execute_reply.started":"2024-11-04T17:02:53.874075Z","shell.execute_reply":"2024-11-04T17:02:53.879866Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"453\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_prompt_formats(sample):\n    \"\"\"\n    Format various fields of the sample ('instruction','output')\n    Then concatenate them using two newline characters \n    :param sample: Sample dictionnary\n    \"\"\"\n    \n    premise = sample['premise']\n    hypothesis = sample['hypothesis']\n    original_label = sample['label']\n    \n    INTRO = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n    \n    INSTRUCTION_KEY = f\"\"\"### Instruct: Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n    0 -> Hypothesis entails the Premise\n    1 -> Premise and Hypothesis neither entail nor contradict each other \n    2 -> Hypothesis contradicts the Premise \n    Output only one single numerical value.\n    \n    Premise: {premise}\n    Hypothesis: {hypothesis}\n    \n    ### Output: {original_label}\"\"\"\n    \n    END_KEY = \"### End\"\n    \n    intro = f\"\\n{INTRO}\"\n    \n    instruction = f\"{INSTRUCTION_KEY}\"\n        \n    end = f\"{END_KEY}\"\n    \n    parts = [intro, instruction, end]\n\n    formatted_prompt = \"\\n\\n\".join(parts)\n    sample[\"text\"] = formatted_prompt\n\n    return sample","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:02:53.882177Z","iopub.execute_input":"2024-11-04T17:02:53.882465Z","iopub.status.idle":"2024-11-04T17:02:53.892932Z","shell.execute_reply.started":"2024-11-04T17:02:53.882433Z","shell.execute_reply":"2024-11-04T17:02:53.891974Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length\n\n\ndef preprocess_batch(batch, tokenizer, max_length):\n    \"\"\"\n    Tokenizing a batch\n    \"\"\"\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )\n\ndef preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n    \"\"\"Format & tokenize it so it is ready for training\n    :param tokenizer (AutoTokenizer): Model Tokenizer\n    :param max_length (int): Maximum number of tokens to emit from tokenizer\n    \"\"\"\n    \n    # Add prompt to each sample\n    print(\"Preprocessing dataset...\")\n    dataset = dataset.map(create_prompt_formats)#, batched=True)\n    \n    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n    dataset = dataset.map(\n        _preprocessing_function,\n        batched=True,\n        remove_columns=['premise', 'hypothesis', 'label'],\n    )\n\n    # Filter out samples that have input_ids exceeding max_length\n    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n    \n    # Shuffle dataset\n    dataset = dataset.shuffle(seed=seed)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:02:53.893980Z","iopub.execute_input":"2024-11-04T17:02:53.894269Z","iopub.status.idle":"2024-11-04T17:02:53.910583Z","shell.execute_reply.started":"2024-11-04T17:02:53.894207Z","shell.execute_reply":"2024-11-04T17:02:53.909757Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\nmax_length = get_max_length(original_model)\nprint(\"Max Length: \", max_length)\n\ntrain_dataset = preprocess_dataset(tokenizer, max_length,seed, new_train_dataset)\neval_dataset = preprocess_dataset(tokenizer, max_length,seed, new_val_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:02:53.911513Z","iopub.execute_input":"2024-11-04T17:02:53.911822Z","iopub.status.idle":"2024-11-04T17:03:00.698734Z","shell.execute_reply.started":"2024-11-04T17:02:53.911774Z","shell.execute_reply":"2024-11-04T17:03:00.697858Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found max lenth: 2048\nMax Length:  2048\nPreprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f44fc3c86c234dbeb11d9956173061a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23626779fbf046ecb209ea1d4983c805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a49aed82c8842e59e30c7fdc0800a0e"}},"metadata":{}},{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77bfb044df284831ada2e8d1bc1160a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d802c436660e490a83fe7e748b8fd259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"384b85f0c7b4405698fcf1f0b070dfc5"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom peft import prepare_model_for_kbit_training\n\noriginal_model = prepare_model_for_kbit_training(original_model)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:00.700033Z","iopub.execute_input":"2024-11-04T17:03:00.700714Z","iopub.status.idle":"2024-11-04T17:03:00.718190Z","shell.execute_reply.started":"2024-11-04T17:03:00.700666Z","shell.execute_reply":"2024-11-04T17:03:00.717376Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# 2 - Using the prepare_model_for_kbit_training method from PEFT\n# Preparing the Model for QLoRA\noriginal_model = prepare_model_for_kbit_training(original_model)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:00.719302Z","iopub.execute_input":"2024-11-04T17:03:00.719676Z","iopub.status.idle":"2024-11-04T17:03:00.730707Z","shell.execute_reply.started":"2024-11-04T17:03:00.719634Z","shell.execute_reply":"2024-11-04T17:03:00.729811Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nconfig = LoraConfig(\n    r=32, #Rank\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"CAUSAL_LM\",\n)\n\n# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\noriginal_model.gradient_checkpointing_enable()\n\npeft_model = get_peft_model(original_model, config)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:00.731871Z","iopub.execute_input":"2024-11-04T17:03:00.732153Z","iopub.status.idle":"2024-11-04T17:03:01.142783Z","shell.execute_reply.started":"2024-11-04T17:03:00.732123Z","shell.execute_reply":"2024-11-04T17:03:01.141963Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    # Count the total number of trainable parameters\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    # Count the total number of parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(f\"Trainable Parameters: {trainable_params}\")\n    print(f\"Total Parameters: {total_params}\")\n    print(f\"Percentage of Trainable Parameters: {100 * trainable_params / total_params:.2f}%\")\n    return trainable_params\n\n\nnum_trainable_params = print_number_of_trainable_model_parameters(peft_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:01.144092Z","iopub.execute_input":"2024-11-04T17:03:01.144605Z","iopub.status.idle":"2024-11-04T17:03:01.163156Z","shell.execute_reply.started":"2024-11-04T17:03:01.144561Z","shell.execute_reply":"2024-11-04T17:03:01.162242Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Trainable Parameters: 20971520\nTotal Parameters: 1542364160\nPercentage of Trainable Parameters: 1.36%\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\nimport time\n\n# Customized output directory name\noutput_dir = './peft-nli-training-checkpoints'\n\n# Set up TrainingArguments with evaluation and checkpointing after every epoch\npeft_training_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=5,  # Number of epochs to train\n    warmup_steps=1,\n    per_device_train_batch_size=4,  # Increased batch size\n    gradient_accumulation_steps=2,  # Reduced accumulation steps\n    learning_rate=5e-4,  # Higher learning rate\n    optim=\"adamw_8bit\",  # 8-bit optimizer\n    logging_steps=100,  # Less frequent logging\n    logging_dir=\"./logs\",\n    save_strategy=\"epoch\",  # Save checkpoint after every epoch\n    evaluation_strategy=\"epoch\",  # Evaluate after every epoch\n    do_eval=True,  # Perform evaluation during training\n    gradient_checkpointing=False,  # Disable if memory allows\n    report_to=\"none\",\n    overwrite_output_dir=False,  # Ensures checkpoints are saved without overwriting\n    group_by_length=True,\n)\n\n# Ensure cache is not used if not necessary\npeft_model.config.use_cache = False\n\n# Define the trainer with the specified arguments\npeft_trainer = Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    args=peft_training_args,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n\n# Start training with automatic evaluation and checkpoint saving after each epoch\n# peft_trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:01.164547Z","iopub.execute_input":"2024-11-04T17:03:01.164876Z","iopub.status.idle":"2024-11-04T17:03:01.209136Z","shell.execute_reply.started":"2024-11-04T17:03:01.164840Z","shell.execute_reply":"2024-11-04T17:03:01.208247Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import time\nimport psutil\nimport torch\n\ndef log_resources(initial=False):\n    # System memory\n    memory = psutil.virtual_memory()\n    if initial:\n        global initial_memory_used\n        initial_memory_used = memory.used\n    print(f\"Total Memory: {memory.total / (1024 ** 3):.2f} GB\")\n    print(f\"Available Memory: {memory.available / (1024 ** 3):.2f} GB\")\n    print(f\"Used Memory: {memory.used / (1024 ** 3):.2f} GB\")\n    \n    # GPU memory (if using CUDA)\n    if torch.cuda.is_available():\n        if initial:\n            global initial_cuda_memory_used\n            initial_cuda_memory_used = torch.cuda.memory_allocated(0)\n        print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n        print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n        print(f\"CUDA Memory Cached: {torch.cuda.memory_reserved(0) / (1024 ** 3):.2f} GB\")\n\n# Start training and calculate the time taken\nstart_time = time.time()\n\n# # Log initial resources and store initial memory usage\n# log_resources(initial=True)\n\nif torch.cuda.is_available():\n    torch.cuda.reset_peak_memory_stats()\n    torch.cuda.synchronize()\n\n# Start the fine-tuning process\npeft_trainer.train()\n\n# # Log resources after training\n# log_resources()\n\n# Calculate time taken\nend_time = time.time()\ntime_taken = end_time - start_time\n\nif torch.cuda.is_available():\n    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)  # Convert to GB\n    print(f\"Peak Memory Usage (GB): {peak_memory:.2f}\")\nelse:\n    peak_memory = None\n    print(\"CUDA not available; unable to track peak memory usage.\")\n\nprint(f\"Time taken for fine-tuning: {time_taken / 60:.2f} minutes\")\n\n# # Calculate memory used during training\n# memory_used = psutil.virtual_memory().used - initial_memory_used\n# print(f\"System Memory Used during fine-tuning: {memory_used / (1024 ** 3):.2f} GB\")\n\n# # Calculate GPU memory used during training (if using CUDA)\n# if torch.cuda.is_available():\n#     cuda_memory_used = torch.cuda.memory_allocated(0) - initial_cuda_memory_used\n#     print(f\"CUDA Memory Used during fine-tuning: {cuda_memory_used / (1024 ** 3):.2f} GB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:03:01.210337Z","iopub.execute_input":"2024-11-04T17:03:01.210650Z","iopub.status.idle":"2024-11-04T17:41:18.548014Z","shell.execute_reply.started":"2024-11-04T17:03:01.210616Z","shell.execute_reply":"2024-11-04T17:41:18.547034Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [625/625 38:12, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.576300</td>\n      <td>0.471104</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.418700</td>\n      <td>0.458096</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.372700</td>\n      <td>0.472280</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"name":"stdout","text":"Peak Memory Usage (GB): 3.34\nTime taken for fine-tuning: 38.29 minutes\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nbase_model_id = \"microsoft/phi-2\"\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n                                                      device_map='auto',\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:18.549256Z","iopub.execute_input":"2024-11-04T17:41:18.549575Z","iopub.status.idle":"2024-11-04T17:41:22.079617Z","shell.execute_reply.started":"2024-11-04T17:41:18.549541Z","shell.execute_reply":"2024-11-04T17:41:22.078639Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"586a7592ef704f2798d6ec69502db718"}},"metadata":{}}]},{"cell_type":"code","source":"eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\neval_tokenizer.pad_token = eval_tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:22.081076Z","iopub.execute_input":"2024-11-04T17:41:22.081397Z","iopub.status.idle":"2024-11-04T17:41:22.265020Z","shell.execute_reply.started":"2024-11-04T17:41:22.081364Z","shell.execute_reply":"2024-11-04T17:41:22.264008Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\n# Directory path\ndirectory = \"/kaggle/working/peft-nli-training-checkpoints\"\n\n# List all files in the directory along with their creation times\nfile_list = os.listdir(directory)\n\n# Sort files by creation time (latest first)\nfile_list = sorted(file_list, key=lambda file: os.path.getctime(os.path.join(directory, file)), reverse=True)\n\n# Print each file's full path with its creation time\nfor file in file_list:\n    file_path = os.path.join(directory, file)\n    creation_time = os.path.getctime(file_path)  # Get the creation time\n    readable_time = datetime.fromtimestamp(creation_time).strftime('%Y-%m-%d %H:%M:%S')\n    print(f\"{file_path} - Created on: {readable_time}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:22.266265Z","iopub.execute_input":"2024-11-04T17:41:22.266589Z","iopub.status.idle":"2024-11-04T17:41:22.276341Z","shell.execute_reply.started":"2024-11-04T17:41:22.266557Z","shell.execute_reply":"2024-11-04T17:41:22.275432Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/working/peft-nli-training-checkpoints/checkpoint-625 - Created on: 2024-11-04 17:41:04\n/kaggle/working/peft-nli-training-checkpoints/checkpoint-502 - Created on: 2024-11-04 17:33:44\n/kaggle/working/peft-nli-training-checkpoints/checkpoint-376 - Created on: 2024-11-04 17:26:03\n/kaggle/working/peft-nli-training-checkpoints/checkpoint-251 - Created on: 2024-11-04 17:18:23\n/kaggle/working/peft-nli-training-checkpoints/checkpoint-125 - Created on: 2024-11-04 17:10:42\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import PeftModel\n\nft_model = PeftModel.from_pretrained(base_model, \"/kaggle/working/peft-nli-training-checkpoints/checkpoint-625\",torch_dtype=torch.float16,is_trainable=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:22.277542Z","iopub.execute_input":"2024-11-04T17:41:22.277886Z","iopub.status.idle":"2024-11-04T17:41:22.870544Z","shell.execute_reply.started":"2024-11-04T17:41:22.277854Z","shell.execute_reply":"2024-11-04T17:41:22.869546Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def zero_shot_inference(model, tokenizer, premise, hypothesis):\n    # Create a formatted prompt\n    formatted_prompt = f\"\"\"Instruct: Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n    0 -> Hypothesis entails the Premise\n    1 -> Premise and Hypothesis neither entail nor contradict each other \n    2 -> Hypothesis contradicts the Premise \n    Output only one single numerical value.\n\n    Premise: {premise}\n    Hypothesis: {hypothesis}\n\n    Output:\n    \"\"\"\n    \n    # Tokenize the input\n    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     print(\"input_ids: \", input_ids)\n#     print(\"Len: \", input_ids.size(1))\n    model.to(input_ids.device)\n    \n    # Generate output\n    with torch.no_grad():\n        generated_ids = model.generate(input_ids, max_length=input_ids.size(1)+10)\n        \n    # Decode and process the model's output\n    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n#     print(output)\n    answer = None\n    try:\n        answer = int((output.split(\"Output:\\n\")[-1].strip().split(\"\\n\")[0]).split(\" \")[0])\n    except:\n        answer = None\n    return formatted_prompt, answer","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:22.872370Z","iopub.execute_input":"2024-11-04T17:41:22.872746Z","iopub.status.idle":"2024-11-04T17:41:22.881910Z","shell.execute_reply.started":"2024-11-04T17:41:22.872710Z","shell.execute_reply":"2024-11-04T17:41:22.880954Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Example data for entailment\ncorrect = 0\ntotal = len(new_test_dataset)\nincorrect = 0\noutput_labels_after_finetuning = []\nfor index in range(0, len(new_test_dataset)):\n    \n    print(\"Index: \", index)\n    \n    premise = new_test_dataset[index]['premise']\n    hypothesis = new_test_dataset[index]['hypothesis']\n    original_label = new_test_dataset[index]['label']\n\n    # Perform zero-shot inference\n    formatted_prompt, output = zero_shot_inference(ft_model, tokenizer, premise, hypothesis)\n    \n#     print(\"Output: \", output)\n#     print(\"UPDATED: \", output+1)\n#     print(original_label)\n    \n#     print(\"Len of prompt: \", len(formatted_prompt))\n    \n    if(output==None):\n        total-=1\n        incorrect+=1\n    elif(int(output) == int(original_label)):\n        correct+=1\n        \n    output_labels_after_finetuning.append(int(output))\n        \n#     if(index==5):\n#         break\n\n# Print results\ndash_line = '-' * 100\nprint(dash_line)\n# print(f'INPUT PROMPT:\\n{formatted_prompt}')\n# print(dash_line)\n# print(f'BASELINE LABEL:\\n{original_label}\\n')\n# print(dash_line)\n# print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\naccuracy = correct/total * 100\n\nprint(\"Accuracy after fine-tuning: \", accuracy)\nprint(\"Samples in incorrect format: \", incorrect)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:41:22.883196Z","iopub.execute_input":"2024-11-04T17:41:22.883597Z","iopub.status.idle":"2024-11-04T17:43:03.046742Z","shell.execute_reply.started":"2024-11-04T17:41:22.883558Z","shell.execute_reply":"2024-11-04T17:43:03.045846Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  0\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  1\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  2\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  3\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  4\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  5\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  6\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  7\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  8\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  9\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  10\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  11\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  12\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  13\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  14\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  15\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  16\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  17\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  18\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  19\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  20\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  21\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  22\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  23\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  24\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  25\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  26\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  27\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  28\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  29\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  30\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  31\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  32\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  33\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  34\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  35\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  36\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  37\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  38\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  39\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  40\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  41\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  42\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  43\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  44\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  45\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  46\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  47\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  48\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  49\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  50\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  51\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  52\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  53\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  54\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  55\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  56\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  57\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  58\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  59\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  60\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  61\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  62\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  63\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  64\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  65\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  66\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  67\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  68\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  69\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  70\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  71\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  72\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  73\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  74\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  75\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  76\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  77\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  78\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  79\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  80\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  81\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  82\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  83\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  84\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  85\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  86\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  87\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  88\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  89\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  90\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  91\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  92\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  93\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  94\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  95\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  96\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  97\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  98\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Index:  99\n----------------------------------------------------------------------------------------------------\nAccuracy after fine-tuning:  88.0\nSamples in incorrect format:  0\n","output_type":"stream"}]},{"cell_type":"code","source":"### Downloading the Model Checkpoints\n\n!zip -r file.zip /kaggle/working/peft-nli-training-checkpoints\n\n!ls\n\nfrom IPython.display import FileLink\nFileLink(r'file.zip')\n\nimport zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    \"\"\"\n    zip all the files in a directory\n    \n    Parameters\n    _____\n    directory: str\n        directory needs to be zipped, defualt is current working directory\n        \n    file_name: str\n        the name of the zipped file (including .zip), default is 'directory.zip'\n        \n    Returns\n    _____\n    Creates a hyperlink, which can be used to download the zip file)\n    \"\"\"\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n                \n    file_size = os.path.getsize(file_name)\n    readable_size = file_size / (1024 ** 2)  # Convert to MB\n    print(f\"Created zip file '{file_name}' with size: {readable_size:.2f} MB\")\n\n    return FileLink(file_name)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:03.048168Z","iopub.execute_input":"2024-11-04T17:43:03.048566Z","iopub.status.idle":"2024-11-04T17:43:36.606712Z","shell.execute_reply.started":"2024-11-04T17:43:03.048522Z","shell.execute_reply":"2024-11-04T17:43:36.605570Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/peft-nli-training-checkpoints/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/rng_state.pth (deflated 25%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/optimizer.pt (deflated 10%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/scheduler.pt (deflated 55%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/adapter_config.json (deflated 53%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/trainer_state.json (deflated 68%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-502/README.md (deflated 66%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/rng_state.pth (deflated 25%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/optimizer.pt (deflated 10%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/scheduler.pt (deflated 56%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/adapter_config.json (deflated 53%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/trainer_state.json (deflated 65%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-376/README.md (deflated 66%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/rng_state.pth (deflated 25%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/optimizer.pt (deflated 10%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/scheduler.pt (deflated 56%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/adapter_config.json (deflated 53%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/trainer_state.json (deflated 56%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-125/README.md (deflated 66%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/rng_state.pth (deflated 25%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/optimizer.pt (deflated 11%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/scheduler.pt (deflated 56%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/adapter_config.json (deflated 53%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/trainer_state.json (deflated 70%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-625/README.md (deflated 66%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/ (stored 0%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/rng_state.pth (deflated 25%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/optimizer.pt (deflated 10%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/scheduler.pt (deflated 56%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/adapter_config.json (deflated 53%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/trainer_state.json (deflated 61%)\n  adding: kaggle/working/peft-nli-training-checkpoints/checkpoint-251/README.md (deflated 66%)\nfile.zip  peft-nli-training-checkpoints\n","output_type":"stream"}]},{"cell_type":"code","source":"zip_dir()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:36.612599Z","iopub.execute_input":"2024-11-04T17:43:36.612924Z","iopub.status.idle":"2024-11-04T17:43:39.628035Z","shell.execute_reply.started":"2024-11-04T17:43:36.612891Z","shell.execute_reply":"2024-11-04T17:43:39.627093Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Created zip file 'directory.zip' with size: 1158.37 MB\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/directory.zip","text/html":"<a href='directory.zip' target='_blank'>directory.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"new_test_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:39.629360Z","iopub.execute_input":"2024-11-04T17:43:39.629756Z","iopub.status.idle":"2024-11-04T17:43:39.636608Z","shell.execute_reply.started":"2024-11-04T17:43:39.629705Z","shell.execute_reply":"2024-11-04T17:43:39.635681Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n 'hypothesis': 'The church has cracks in the ceiling.',\n 'label': 1}"},"metadata":{}}]},{"cell_type":"code","source":"### Pretrained Model vs Finetuned Model\n\noriginal_labels = []\n\npretrained_incorrect_finetuned_correct = []\npretrained_incorrect_finetuned_incorrect = []\npretrained_correct_finetuned_incorrect = []\n\n\nfor row in new_test_dataset:\n    original_labels.append(row['label'])\n    \nfor index in range(0, len(new_test_dataset)):\n    pretrained_model_label = output_labels_before_finetuning[index]\n    finetuned_model_label = output_labels_after_finetuning[index]\n    original_label = original_labels[index]\n    sample = new_test_dataset[index]\n    \n    if(pretrained_model_label != original_label and finetuned_model_label == original_label):\n        sample['pretrained_label']=pretrained_model_label\n        sample['finetuned_label']=finetuned_model_label\n        pretrained_incorrect_finetuned_correct.append(sample)\n    elif(pretrained_model_label != original_label and finetuned_model_label != original_label):\n        sample['pretrained_label']=pretrained_model_label\n        sample['finetuned_label']=finetuned_model_label\n        pretrained_incorrect_finetuned_incorrect.append(sample)\n    elif(pretrained_model_label == original_label and finetuned_model_label != original_label):\n        sample['pretrained_label']=pretrained_model_label\n        sample['finetuned_label']=finetuned_model_label\n        pretrained_correct_finetuned_incorrect.append(sample)\n        \n        \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:39.638133Z","iopub.execute_input":"2024-11-04T17:43:39.638426Z","iopub.status.idle":"2024-11-04T17:43:39.668083Z","shell.execute_reply.started":"2024-11-04T17:43:39.638395Z","shell.execute_reply":"2024-11-04T17:43:39.667124Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Define the directory and filenames\noutput_directory = \"./saved_results\"\nos.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n\n# Save each list as a separate JSON file\nwith open(os.path.join(output_directory, 'pretrained_incorrect_finetuned_correct.json'), 'w') as f:\n    json.dump(pretrained_incorrect_finetuned_correct, f, indent=4)\n\nwith open(os.path.join(output_directory, 'pretrained_incorrect_finetuned_incorrect.json'), 'w') as f:\n    json.dump(pretrained_incorrect_finetuned_incorrect, f, indent=4)\n\nwith open(os.path.join(output_directory, 'pretrained_correct_finetuned_incorrect.json'), 'w') as f:\n    json.dump(pretrained_correct_finetuned_incorrect, f, indent=4)\n\nprint(\"Lists saved successfully in JSON format.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:39.669210Z","iopub.execute_input":"2024-11-04T17:43:39.669510Z","iopub.status.idle":"2024-11-04T17:43:39.679042Z","shell.execute_reply.started":"2024-11-04T17:43:39.669479Z","shell.execute_reply":"2024-11-04T17:43:39.677949Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Lists saved successfully in JSON format.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"The number of samples:\\n\")\nprint(\"Pretrained: Incorrect, Finetuned: Correct ->\", len(pretrained_incorrect_finetuned_correct))\nprint(\"Pretrained: Incorrect, Finetuned: Incorrect ->\", len(pretrained_incorrect_finetuned_incorrect))\nprint(\"Pretrained: Correct, Finetuned: Incorrect ->\", len(pretrained_correct_finetuned_incorrect))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:39.680257Z","iopub.execute_input":"2024-11-04T17:43:39.680585Z","iopub.status.idle":"2024-11-04T17:43:39.691832Z","shell.execute_reply.started":"2024-11-04T17:43:39.680554Z","shell.execute_reply":"2024-11-04T17:43:39.690850Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The number of samples:\n\nPretrained: Incorrect, Finetuned: Correct -> 49\nPretrained: Incorrect, Finetuned: Incorrect -> 10\nPretrained: Correct, Finetuned: Incorrect -> 2\n","output_type":"stream"}]},{"cell_type":"code","source":"### Downloading the Model Checkpoints\n\n!zip -r file.zip /kaggle/working/saved_results\n\n!ls\n\nfrom IPython.display import FileLink\nFileLink(r'file.zip')\n\nimport zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    \"\"\"\n    zip all the files in a directory\n    \n    Parameters\n    _____\n    directory: str\n        directory needs to be zipped, defualt is current working directory\n        \n    file_name: str\n        the name of the zipped file (including .zip), default is 'directory.zip'\n        \n    Returns\n    _____\n    Creates a hyperlink, which can be used to download the zip file)\n    \"\"\"\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n                \n    file_size = os.path.getsize(file_name)\n    readable_size = file_size / (1024 ** 2)  # Convert to MB\n    print(f\"Created zip file '{file_name}' with size: {readable_size:.2f} MB\")\n\n    return FileLink(file_name)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:39.692885Z","iopub.execute_input":"2024-11-04T17:43:39.693188Z","iopub.status.idle":"2024-11-04T17:43:42.474065Z","shell.execute_reply.started":"2024-11-04T17:43:39.693147Z","shell.execute_reply":"2024-11-04T17:43:42.472955Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/saved_results/ (stored 0%)\n  adding: kaggle/working/saved_results/pretrained_correct_finetuned_incorrect.json (deflated 57%)\n  adding: kaggle/working/saved_results/pretrained_incorrect_finetuned_correct.json (deflated 79%)\n  adding: kaggle/working/saved_results/pretrained_incorrect_finetuned_incorrect.json (deflated 72%)\ndirectory.zip  file.zip  peft-nli-training-checkpoints\tsaved_results\n","output_type":"stream"}]},{"cell_type":"code","source":"zip_dir()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:43:42.475553Z","iopub.execute_input":"2024-11-04T17:43:42.475885Z","iopub.status.idle":"2024-11-04T17:43:45.827390Z","shell.execute_reply.started":"2024-11-04T17:43:42.475851Z","shell.execute_reply":"2024-11-04T17:43:45.826397Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Created zip file 'directory.zip' with size: 1158.38 MB\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/directory.zip","text/html":"<a href='directory.zip' target='_blank'>directory.zip</a><br>"},"metadata":{}}]}]}